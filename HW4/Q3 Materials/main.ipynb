{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-29T02:05:59.257230Z","iopub.status.busy":"2024-01-29T02:05:59.256765Z","iopub.status.idle":"2024-01-29T02:06:02.187800Z","shell.execute_reply":"2024-01-29T02:06:02.186868Z","shell.execute_reply.started":"2024-01-29T02:05:59.257189Z"},"trusted":true},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from os import path\n","from torch.utils.data import Dataset, DataLoader, random_split\n","from tqdm import tqdm\n","from torch import tensor"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:02.190111Z","iopub.status.busy":"2024-01-29T02:06:02.189656Z","iopub.status.idle":"2024-01-29T02:06:02.226692Z","shell.execute_reply":"2024-01-29T02:06:02.225456Z","shell.execute_reply.started":"2024-01-29T02:06:02.190077Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["using cuda device\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","print(f\"using {device} device\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:02.229016Z","iopub.status.busy":"2024-01-29T02:06:02.228313Z","iopub.status.idle":"2024-01-29T02:06:02.342188Z","shell.execute_reply":"2024-01-29T02:06:02.341001Z","shell.execute_reply.started":"2024-01-29T02:06:02.228982Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["number of lines: 99217\n"]}],"source":["file_path = '/kaggle/input/ferdousi-txt/ferdousi.txt'\n","\n","# read the file and igoore the first 2 lines\n","with open(file_path, 'r') as f:\n","    lines = f.readlines()[2:]\n","\n","print(f\"number of lines: {len(lines)}\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:02.345165Z","iopub.status.busy":"2024-01-29T02:06:02.344873Z","iopub.status.idle":"2024-01-29T02:06:02.359616Z","shell.execute_reply":"2024-01-29T02:06:02.358514Z","shell.execute_reply.started":"2024-01-29T02:06:02.345139Z"},"trusted":true},"outputs":[],"source":["# Create dataset    \n","class FerdousiDataset(Dataset):\n","    def __init__(self, root_dir, transform=None):\n","        self.root_dir = root_dir\n","        # self.transform = transform\n","        self.lines = self.load_lines()\n","        self.data = self._load_data()\n","\n","    def load_lines(self):\n","        with open(self.root_dir, 'r') as f:\n","            lines = f.readlines()\n","        \n","        lines = [line.strip('\\n') for line in lines[2:]]\n","        lines = lines[:2 * (len(lines) // 2)]\n","        return lines\n","    \n","    def __len__(self):\n","        return self.data['len']\n","    \n","    def _load_data(self):\n","        lines = self.lines\n","        \n","        # Split into santzes and lengths\n","        data ={\n","           'stanza_1': lines[0::2],\n","            'stanza_2': lines[1::2],\n","            'len': len(lines) // 2,\n","        }\n","        return data\n","\n","    def __getitem__(self, idx):\n","        data = self.data\n","        if idx >= data['len']:\n","            raise IndexError(\"index out of range\")\n","            \n","        return data['stanza_1'][idx], data['stanza_2'][idx]\n","        \n","\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:02.361279Z","iopub.status.busy":"2024-01-29T02:06:02.360974Z","iopub.status.idle":"2024-01-29T02:06:02.453217Z","shell.execute_reply":"2024-01-29T02:06:02.452249Z","shell.execute_reply.started":"2024-01-29T02:06:02.361254Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["stanza 1: به نام خداوند جان و خرد\n","stanza 2: کزین برتر اندیشه برنگذرد\n","\n","stanza 1: خداوند نام و خداوند جای\n","stanza 2: خداوند روزی ده رهنمای\n","\n","stanza 1: خداوند کیوان و گردان سپهر\n","stanza 2: فروزنده ماه و ناهید و مهر\n","\n","stanza 1: ز نام و نشان و گمان برترست\n","stanza 2: نگارندهٔ بر شده پیکرست\n","\n","stanza 1: به بینندگان آفریننده را\n","stanza 2: نبینی مرنجان دو بیننده را\n","\n"]}],"source":["# Create dataset\n","dataset = FerdousiDataset(file_path)\n","\n","# Split into train and test\n","train_size = int(0.8 * len(dataset))\n","test_size = len(dataset) - train_size\n","train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n","\n","# Print samples from the dataset\n","for i in range(5):\n","    print(f\"stanza 1: {dataset[i][0]}\")\n","    print(f\"stanza 2: {dataset[i][1]}\")\n","    # print(f\"len: {dataset[i][2]}\")\n","    print()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:02.455238Z","iopub.status.busy":"2024-01-29T02:06:02.454382Z","iopub.status.idle":"2024-01-29T02:06:04.530250Z","shell.execute_reply":"2024-01-29T02:06:04.529303Z","shell.execute_reply.started":"2024-01-29T02:06:02.455204Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n","\n","model_name = \"HooshvareLab/gpt2-fa\""]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:04.533773Z","iopub.status.busy":"2024-01-29T02:06:04.533370Z","iopub.status.idle":"2024-01-29T02:06:04.539438Z","shell.execute_reply":"2024-01-29T02:06:04.538595Z","shell.execute_reply.started":"2024-01-29T02:06:04.533747Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["خداوند روزی ده رهنمای\n"]}],"source":["print(dataset[1][1])"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T03:57:50.202953Z","iopub.status.busy":"2024-01-29T03:57:50.201963Z","iopub.status.idle":"2024-01-29T03:57:50.532979Z","shell.execute_reply":"2024-01-29T03:57:50.531981Z","shell.execute_reply.started":"2024-01-29T03:57:50.202916Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["GPT2Config {\n","  \"_name_or_path\": \"HooshvareLab/gpt2-fa\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 5,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 5,\n","  \"gradient_checkpointing\": false,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 768,\n","  \"n_head\": 12,\n","  \"n_inner\": null,\n","  \"n_layer\": 12,\n","  \"n_positions\": 1024,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50,\n","      \"top_k\": 50,\n","      \"top_p\": 0.95\n","    }\n","  },\n","  \"transformers_version\": \"4.36.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 42001\n","}\n","\n"]}],"source":["special_tokens = {\n","    \"pad_token\": \"<pad>\",\n","    \"unk_token\": \"<unk>\",\n","    \"bos_token\": \"<bos>\",\n","    \"eos_token\": \"<eos>\",\n","    \"sep_token\": \"<sep>\",\n","}\n","\n","# Make tokenizer specific to Persian\n","opt ={\n","    **special_tokens,\n","    \"padding_side\": \"right\",\n","    \"model_max_length\": 20,\n","    \"model_name\": model_name,\n","}\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, **opt)\n","\n","tokenizer.add_special_tokens(special_tokens)\n","\n","config = AutoConfig.from_pretrained(model_name)\n","\n","print(config)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:06.795141Z","iopub.status.busy":"2024-01-29T02:06:06.794859Z","iopub.status.idle":"2024-01-29T02:06:06.804032Z","shell.execute_reply":"2024-01-29T02:06:06.802812Z","shell.execute_reply.started":"2024-01-29T02:06:06.795116Z"},"trusted":true},"outputs":[],"source":["class TokenizedDataset(Dataset):\n","    def __init__(self, dataset, tokenizer):\n","        self.tokenizer = tokenizer\n","        self.dataset = dataset\n","        self.encodings = {'input_ids': [], 'labels': [], 'attention_mask': []}\n","        \n","        for stanza_1, stanza_2 in tqdm(dataset, desc='Tokenizing'):\n","            input_enc = tokenizer(\n","                f\"{tokenizer.bos_token}{stanza_1}{tokenizer.sep_token}{stanza_2}{tokenizer.eos_token}\", \n","                truncation=True,\n","                padding=\"max_length\"\n","            )\n","\n","            target_enc = tokenizer(\n","                f\"{tokenizer.bos_token}{stanza_1}{tokenizer.sep_token}{stanza_2}{tokenizer.eos_token}\", \n","                truncation=True,\n","                padding=\"max_length\"\n","            )\n","            \n","            self.encodings['input_ids'].append(tensor(input_enc['input_ids']))\n","            self.encodings['labels'].append(tensor(target_enc['input_ids']))\n","            self.encodings['attention_mask'].append(tensor(input_enc['attention_mask']))\n","\n","    def __getitem__(self, idx):\n","        return {key: value[idx].clone().detach() for key, value in self.encodings.items()}\n","\n","    def __len__(self):\n","        return len(self.dataset)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:06.807291Z","iopub.status.busy":"2024-01-29T02:06:06.806988Z","iopub.status.idle":"2024-01-29T02:06:25.085009Z","shell.execute_reply":"2024-01-29T02:06:25.083991Z","shell.execute_reply.started":"2024-01-29T02:06:06.807267Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Tokenizing: 100%|██████████| 39686/39686 [00:14<00:00, 2757.49it/s]\n","Tokenizing: 100%|██████████| 9922/9922 [00:03<00:00, 2565.13it/s]\n"]}],"source":["tokenized_dataset_train = TokenizedDataset(train_dataset, tokenizer)\n","tokenized_dataset_test = TokenizedDataset(test_dataset, tokenizer)\n","\n","batch_size = 128\n","\n","train_dataloader = DataLoader(\n","    tokenized_dataset_train,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=os.cpu_count(),\n","    pin_memory=False\n",")\n","test_dataloader = DataLoader(\n","    tokenized_dataset_test,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=os.cpu_count(),\n","    pin_memory=False\n",")\n","\n","if os.cpu_count() > 1:\n","    os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:25.086783Z","iopub.status.busy":"2024-01-29T02:06:25.086328Z","iopub.status.idle":"2024-01-29T02:06:25.092019Z","shell.execute_reply":"2024-01-29T02:06:25.091122Z","shell.execute_reply.started":"2024-01-29T02:06:25.086749Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["number of train batches: 311\n","dict_keys(['input_ids', 'labels', 'attention_mask'])\n"]}],"source":["print(f\"number of train batches: {len(train_dataloader)}\")\n","# print encodings\n","print(train_dataloader.dataset.encodings.keys())"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:25.093661Z","iopub.status.busy":"2024-01-29T02:06:25.093319Z","iopub.status.idle":"2024-01-29T02:06:29.164272Z","shell.execute_reply":"2024-01-29T02:06:29.163338Z","shell.execute_reply.started":"2024-01-29T02:06:25.093629Z"},"trusted":true},"outputs":[{"data":{"text/plain":["GPT2LMHeadModel(\n","  (transformer): GPT2Model(\n","    (wte): Embedding(42003, 768)\n","    (wpe): Embedding(1024, 768)\n","    (drop): Dropout(p=0.1, inplace=False)\n","    (h): ModuleList(\n","      (0-11): 12 x GPT2Block(\n","        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (attn): GPT2Attention(\n","          (c_attn): Conv1D()\n","          (c_proj): Conv1D()\n","          (attn_dropout): Dropout(p=0.1, inplace=False)\n","          (resid_dropout): Dropout(p=0.1, inplace=False)\n","        )\n","        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (mlp): GPT2MLP(\n","          (c_fc): Conv1D()\n","          (c_proj): Conv1D()\n","          (act): NewGELUActivation()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=42003, bias=False)\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForCausalLM.from_config(config)\n","\n","model.resize_token_embeddings(len(tokenizer))\n","model = model.to(device)\n","\n","model"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:29.166478Z","iopub.status.busy":"2024-01-29T02:06:29.165596Z","iopub.status.idle":"2024-01-29T02:06:29.321032Z","shell.execute_reply":"2024-01-29T02:06:29.319957Z","shell.execute_reply.started":"2024-01-29T02:06:29.166441Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["input_ids shape: torch.Size([128, 50])\n","labels shape: torch.Size([128, 50])\n","attention_mask shape: torch.Size([128, 50])\n"]}],"source":["# Sample from the data loader\n","batch = next(iter(train_dataloader))\n","\n","# Access the input_ids, labels, and attention_mask from the batch\n","input_ids = batch['input_ids']\n","labels = batch['labels']\n","attention_mask = batch['attention_mask']\n","\n","# Print the shapes of the tensors\n","print(f\"input_ids shape: {input_ids.shape}\")\n","print(f\"labels shape: {labels.shape}\")\n","print(f\"attention_mask shape: {attention_mask.shape}\")\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T02:06:29.322915Z","iopub.status.busy":"2024-01-29T02:06:29.322597Z","iopub.status.idle":"2024-01-29T03:35:51.241536Z","shell.execute_reply":"2024-01-29T03:35:51.240618Z","shell.execute_reply.started":"2024-01-29T02:06:29.322887Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20:\n","Train Loss: 2.3532668677940247\n","Val Loss: 2.0957179497449827\n","\n","Epoch 2/20:\n","Train Loss: 1.9384739096141705\n","Val Loss: 1.8498658216916597\n","\n","Epoch 3/20:\n","Train Loss: 1.7709338814499294\n","Val Loss: 1.7182630101839702\n","\n","Epoch 4/20:\n","Train Loss: 1.6701014820019149\n","Val Loss: 1.6328510703184667\n","\n","Epoch 5/20:\n","Train Loss: 1.5832772339271963\n","Val Loss: 1.5537218726598299\n","\n","Epoch 6/20:\n","Train Loss: 1.5001554673124355\n","Val Loss: 1.4861500905110285\n","\n","Epoch 7/20:\n","Train Loss: 1.4222040172558505\n","Val Loss: 1.4157999662252574\n","\n","Epoch 8/20:\n","Train Loss: 1.3485908661624626\n","Val Loss: 1.3565743978206928\n","\n","Epoch 9/20:\n","Train Loss: 1.2795051815425469\n","Val Loss: 1.308380962946476\n","\n","Epoch 10/20:\n","Train Loss: 1.2206347889455569\n","Val Loss: 1.2748454564656966\n","\n","Epoch 11/20:\n","Train Loss: 1.1663779641271022\n","Val Loss: 1.2410783095237536\n","\n","Epoch 12/20:\n","Train Loss: 1.1200137655834677\n","Val Loss: 1.217805871596703\n","\n","Epoch 13/20:\n","Train Loss: 1.0754886911612997\n","Val Loss: 1.2011007849986737\n","\n","Epoch 14/20:\n","Train Loss: 1.0331716407150318\n","Val Loss: 1.186470742409046\n","\n","Epoch 15/20:\n","Train Loss: 0.9923518723613579\n","Val Loss: 1.1760501724023085\n","\n","Epoch 16/20:\n","Train Loss: 0.9516534230333432\n","Val Loss: 1.1679530036755097\n","\n","Epoch 17/20:\n","Train Loss: 0.9110082397506934\n","Val Loss: 1.1658263603846233\n","\n","Epoch 18/20:\n","Train Loss: 0.870873898746883\n","Val Loss: 1.1659600749993935\n","\n","Epoch 19/20:\n","Train Loss: 0.8296782305386289\n","Val Loss: 1.1698217239135351\n","\n","Epoch 20/20:\n","Train Loss: 0.7885451033184383\n","Val Loss: 1.1704262495040894\n","\n","Sample Loss: 0.6600303053855896\n"]}],"source":["num_epochs = 20\n","loss_dict = {'train_losses': [], 'val_losses': [], 'gen_bleu': [], 'perplexity': []}\n","\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n","\n","for epoch in range(num_epochs):\n","    train_losses = []\n","    val_losses = []\n","    gen_bleu = []\n","    perplexity = []\n","\n","    # Training\n","    model.train()\n","    for batch in train_dataloader:\n","        input_ids = batch['input_ids'].to(device)\n","        labels = batch['labels'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(input_ids=input_ids, labels=labels, attention_mask=attention_mask)\n","        loss = outputs.loss\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_losses.append(loss.item())\n","\n","    # Validation\n","    model.eval()\n","    with torch.no_grad():\n","        for batch in test_dataloader:\n","            input_ids = batch['input_ids'].to(device)\n","            labels = batch['labels'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","\n","            outputs = model(input_ids=input_ids, labels=labels, attention_mask=attention_mask)\n","            loss = outputs.loss\n","\n","            val_losses.append(loss.item())\n","\n","    # Update loss_dict\n","    loss_dict['train_losses'].append(sum(train_losses) / len(train_losses))\n","    loss_dict['val_losses'].append(sum(val_losses) / len(val_losses))\n","    loss_dict['gen_bleu'].append(0)  # Replace with your BLEU score calculation\n","    loss_dict['perplexity'].append(0)  # Replace with your perplexity calculation\n","\n","    # Print epoch results\n","    print(f\"Epoch {epoch + 1}/{num_epochs}:\")\n","    print(f\"Train Loss: {loss_dict['train_losses'][-1]}\")\n","    print(f\"Val Loss: {loss_dict['val_losses'][-1]}\")\n","    print()\n","\n","    # Adjust learning rate\n","    scheduler.step()\n","\n","# End of training loop\n","\n","# Print one sample\n","sample_batch = next(iter(train_dataloader))\n","sample_input_ids = sample_batch['input_ids'].to(device)\n","sample_labels = sample_batch['labels'].to(device)\n","sample_attention_mask = sample_batch['attention_mask'].to(device)\n","\n","sample_outputs = model(input_ids=sample_input_ids, labels=sample_labels, attention_mask=sample_attention_mask)\n","sample_loss = sample_outputs.loss\n","\n","print(f\"Sample Loss: {sample_loss.item()}\")\n"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T03:59:17.627045Z","iopub.status.busy":"2024-01-29T03:59:17.626683Z","iopub.status.idle":"2024-01-29T03:59:17.635195Z","shell.execute_reply":"2024-01-29T03:59:17.634150Z","shell.execute_reply.started":"2024-01-29T03:59:17.627018Z"},"trusted":true},"outputs":[],"source":["def generate_sequence(poem, tokenizer, model, device):\n","    gen_encoding = {'input_ids': 0, 'attention_mask': 0}\n","    input_ = tokenizer(\n","        tokenizer.bos_token + poem + tokenizer.sep_token , # Masked auto encoder\n","        truncation=True,\n","        padding=\"max_length\",\n","        return_tensors='pt'\n","    )\n","    gen_encoding['input_ids'] = input_[\"input_ids\"].to(device)\n","    gen_encoding['attention_mask'] = torch.ones_like(gen_encoding['input_ids']).to(device)\n","    outputs = model.generate(\n","        **gen_encoding,\n","        top_k=50,\n","        max_length=30,\n","        num_beams=5,\n","        no_repeat_ngram_size=2,\n","        num_return_sequences=1,\n","        do_sample = False,\n","        pad_token_id=tokenizer.eos_token_id, # Open end generation\n","    )\n","    \n","    in_stanza = tokenizer.decode(gen_encoding['input_ids'][0], skip_special_tokens=True)\n","    out_stanza = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","    out_stanza = out_stanza.replace(in_stanza, in_stanza + '  ,  ')\n","    print('Generated sequence: ')\n","    print(out_stanza)\n","    print(\"  \")"]},{"cell_type":"code","execution_count":60,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T04:00:43.797055Z","iopub.status.busy":"2024-01-29T04:00:43.796678Z","iopub.status.idle":"2024-01-29T04:00:43.801859Z","shell.execute_reply":"2024-01-29T04:00:43.800977Z","shell.execute_reply.started":"2024-01-29T04:00:43.797026Z"},"trusted":true},"outputs":[],"source":["poems = [\n","    'توانا بود هر که دانا بود',\n","    'به نام خداوند جان و خرد',\n","    'هنر نزد ایرانیان است و بس',\n","]\n","\n","not_poems = [\n","    'بفرستین مریض اول رو تو',\n","    'دکی دکی دکی دکی دکی جون',\n","    'محلمون داداشی نوبنیاد تا قاراشی',\n","    'سعیدا مرد نکونام نمیرد هرگز',\n","    'امشب بدجور حالم خراب',\n","]\n"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T04:00:45.957219Z","iopub.status.busy":"2024-01-29T04:00:45.956319Z","iopub.status.idle":"2024-01-29T04:00:46.364488Z","shell.execute_reply":"2024-01-29T04:00:46.363598Z","shell.execute_reply.started":"2024-01-29T04:00:45.957182Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["---------\n","Generated sequence: \n","توانا بود هر که دانا بود  ,   نیستید در سر سر زمین\n","  \n","---------\n","Generated sequence: \n","به نام خداوند جان و خرد  ,   درل گرد و دل دل روان\n","  \n","---------\n","Generated sequence: \n","هنر نزد ایرانیان است و بس  ,   سترخیزید در از سرش\n","  \n"]}],"source":["for poem in poems:\n","    print(\"---------\")\n","    generate_sequence(poem, tokenizer, model, device)"]},{"cell_type":"code","execution_count":62,"metadata":{"execution":{"iopub.execute_input":"2024-01-29T04:00:48.191642Z","iopub.status.busy":"2024-01-29T04:00:48.191265Z","iopub.status.idle":"2024-01-29T04:00:48.854070Z","shell.execute_reply":"2024-01-29T04:00:48.853182Z","shell.execute_reply.started":"2024-01-29T04:00:48.191611Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["----\n","Generated sequence: \n","بفرستین مریض اول رو تو  ,   سترخیزلان اخترگ و دل\n","  \n","----\n","Generated sequence: \n","دکی دکی دکی دکی دکی جون  ,   در در لب رود و روان\n","  \n","----\n","Generated sequence: \n","محلمون داداشی نوبنیاد تا قاراشی  ,  ید در لب گردن افراختند\n","  \n","----\n","Generated sequence: \n","سعیدا مرد نکونام نمیرد هرگز  ,  که آن بر مغل دلگ و تن\n","  \n","----\n","Generated sequence: \n","امشب بدجور حالم خراب  ,   بر در در میدان او سر کنار\n","  \n"]}],"source":["for poem in not_poems:\n","    print(\"----\")\n","    generate_sequence(poem, tokenizer, model, device)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4368320,"sourceId":7501646,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
